{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from https://github.com/Tomjg14/Master_Thesis_MSMARCO_Passage_Reranking_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.13.0+cu116 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSMARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "folder = 'data/msmarco_passage/'\n",
    "tar_file = 'collectionandqueries.tar.gz'\n",
    "tar_file_path = folder + tar_file\n",
    "\n",
    "if not exists(tar_file_path):\n",
    "    print('Downloading ' + tar_file + ' ...')\n",
    "    url = 'https://msmarco.blob.core.windows.net/msmarcoranking/' + tar_file\n",
    "    urllib.request.urlretrieve(url, tar_file_path)\n",
    "\n",
    "    print('Extracting ' + tar_file + ' ...')\n",
    "    with tarfile.open(tar_file_path) as tar:\n",
    "        tar.extractall(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anserini\n",
    "Download/install C++ build tools: https://visualstudio.microsoft.com/visual-cpp-build-tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyserini\n",
    "!pip install faiss-cpu\n",
    "!git clone https://github.com/castorini/anserini.git --recurse-submodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python anserini/tools/scripts/msmarco/convert_collection_to_jsonl.py --collection-path data/msmarco_passage/collection.tsv --output-folder data/msmarco_passage/collection_jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pyserini.index.lucene -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 9 -input data/msmarco_passage/collection_jsonl -index data/msmarco_passage/lucene-index-msmarco-passage -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python anserini/tools/scripts/msmarco/filter_queries.py --qrels data/msmarco_passage/qrels.dev.small.tsv --queries data/msmarco_passage/queries.dev.tsv --output data/msmarco_passage/queries.dev.small.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top 1000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python anserini/tools/scripts/msmarco/retrieve.py --hits 1000 --threads 1 --index data/msmarco_passage/lucene-index-msmarco-passage --queries data/msmarco_passage/queries.dev.small.tsv --output data/output/run.anserini.dev.small.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_pretrained_bert\n",
    "!pip install livelossplot\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install unidecode\n",
    "\n",
    "!pip install ipywidgets==7.* --user\n",
    "!pip install widgetsnbextension jupyter_contrib_nbextensions --user\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import unidecode\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME, BertForMultipleChoice\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.tokenization import (BasicTokenizer,\n",
    "                                                  BertTokenizer,\n",
    "                                                  whitespace_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Tensorflow model to PyTorch (only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!python bert_convert_tensorflow_to_pytorch.py --tf_checkpoint_path=./model/BERT_Base_trained_on_MSMARCO/model.ckpt-100000 --bert_config_file=./model/BERT_Base_trained_on_MSMARCO/bert_config.json --pytorch_dump_path=./model/BERT_Base_trained_on_MSMARCO/pytorch.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the IDs of the previous queries of a query in a session \n",
    "def get_lower_ids(session_df, query_id):\n",
    "    session_id = int(query_id.split('_')[0])\n",
    "    current_id = int(query_id.split('_')[1])\n",
    "    all_ids = [int(x.split('_')[1]) for x in session_df['query_id'].tolist()]\n",
    "    lower_ids = [x for x in all_ids if x < current_id]\n",
    "    lower_ids = [str(session_id) + '_' + str(x) for x in lower_ids]\n",
    "    return lower_ids\n",
    "\n",
    "# function that strips all non-alphanumeric characters\n",
    "def remove_non_alphanumeric(text):\n",
    "    text = unidecode.unidecode(str(text))\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# function that returns a list of segment ids based on indexed tokens (BERT)\n",
    "def get_segment_ids_from_index_tokens(indexed_tokens):\n",
    "    segment_ids = []\n",
    "    sep = False\n",
    "    for i, token in enumerate(indexed_tokens):\n",
    "        if token == 102:\n",
    "            sep = True\n",
    "        if sep:\n",
    "            segment_ids.append(1)\n",
    "        else:\n",
    "            segment_ids.append(0)\n",
    "    return segment_ids\n",
    "\n",
    "def run_bert(data):\n",
    "    activations = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        # convert inputs to PyTorch tensors\n",
    "        tokens = data.iloc[i]['indexed_tokens']\n",
    "        segment_ids = data.iloc[i]['segment_ids']\n",
    "        \n",
    "        # make sure the input fits\n",
    "        token_size_diff = len(tokens) - 512\n",
    "        if token_size_diff > 0:\n",
    "            tokens = [tokens[0]] + tokens[token_size_diff:]\n",
    "            segment_ids = [segment_ids[0]] + segment_ids[token_size_diff:]\n",
    "\n",
    "        tokens_tensor = torch.tensor([tokens])\n",
    "        segments_tensors = torch.tensor([segment_ids])\n",
    "\n",
    "        # set everything to run on GPU\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        segments_tensors = segments_tensors.to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = bertmodel(tokens_tensor, segments_tensors) \n",
    "            activations.append(prediction.cpu())\n",
    "\n",
    "    data['pooled_output'] = activations\n",
    "    return data\n",
    "\n",
    "# https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_filename = 'queries.dev.small.tsv'\n",
    "anserini_output_filename = 'run.anserini.dev.small.tsv'\n",
    "output_filename = 'run.bert.dev.small.tsv'\n",
    "\n",
    "models_dir = \"model/\"\n",
    "msmarco_dir = \"data/msmarco_passage/\"\n",
    "anserini_output_dir = \"data/output/\"\n",
    "output_dir = \"data/output/\"\n",
    "\n",
    "top_n = 100\n",
    "\n",
    "n_chunks = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSMARCO collection\n",
    "msmarco_collection = pd.read_csv(msmarco_dir + 'collection.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "msmarco_collection.columns = ['passage_id', 'passage']\n",
    "\n",
    "query_subset = pd.read_csv(msmarco_dir + queries_filename,delimiter='\\t',encoding='utf-8', header=None)\n",
    "query_subset.columns = ['query_id', 'query']\n",
    "\n",
    "query_anserini_output = pd.read_csv(anserini_output_dir + anserini_output_filename,delimiter='\\t',encoding='utf-8', header=None)\n",
    "query_anserini_output.columns = ['query_id', 'passage_id', 'bm25_rank']\n",
    "\n",
    "top1000_query_ids = pd.DataFrame(list(np.unique(query_anserini_output['query_id'].tolist())))\n",
    "top1000_query_ids.columns = ['query_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "bert_df = top1000_query_ids.copy()\n",
    "bert_df = bert_df.merge(query_anserini_output[query_anserini_output['bm25_rank'] <= top_n],how='left',on=['query_id'])\n",
    "bert_df = bert_df.merge(query_subset,how='left',on=['query_id'])\n",
    "bert_df = bert_df.merge(msmarco_collection,how='left',on=['passage_id'])\n",
    "\n",
    "bert_df['query'] = bert_df['query'].progress_apply(lambda x: remove_non_alphanumeric(x.lower()))\n",
    "tqdm.pandas()\n",
    "bert_df['passage'] = bert_df['passage'].progress_apply(lambda x: remove_non_alphanumeric(x.lower()))\n",
    "bert_df['input_text'] = \"[CLS] \" + bert_df['query'] +\" [SEP] \" + bert_df['passage'] + \" [SEP]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', 2)\n",
    "bertmodel.load_state_dict(torch.load(models_dir + 'BERT_Base_trained_on_MSMARCO/pytorch.bin'))\n",
    "\n",
    "bertmodel.eval()\n",
    "bertmodel.to('cuda')\n",
    "\n",
    "tqdm.pandas()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(query_subset['query_id'])\n",
    "query_id_chunks = list(split(query_ids, n_chunks))\n",
    "\n",
    "for i, query_id_chunk in enumerate(query_id_chunks):\n",
    "    tqdm.write('chunk {}/{}'.format(i + 1, n_chunks))\n",
    "\n",
    "    bert_df_chunk = bert_df[bert_df['query_id'].isin(query_id_chunk)].copy()\n",
    "\n",
    "    # tokenize\n",
    "    tqdm.write('tokenize')\n",
    "\n",
    "    bert_df_chunk['indexed_tokens'] = bert_df_chunk.progress_apply(lambda row: tokenizer.convert_tokens_to_ids(tokenizer.tokenize(row['input_text'])), axis=1)\n",
    "    bert_df_chunk['segment_ids'] = bert_df_chunk.progress_apply(lambda row: get_segment_ids_from_index_tokens(row['indexed_tokens']), axis=1)\n",
    "\n",
    "    # run\n",
    "    tqdm.write('run')\n",
    "    output_df_chunk = run_bert(bert_df_chunk)\n",
    "\n",
    "    # score\n",
    "    output_df_chunk['score_bert'] = output_df_chunk.progress_apply(lambda row: row['pooled_output'].data[0][1].item(), axis=1)\n",
    "    output_df_chunk = output_df_chunk.drop(columns=['input_text', 'indexed_tokens', 'segment_ids', 'pooled_output'])\n",
    "    output_df_chunk[\"bert_rank\"] = output_df_chunk.groupby(\"query_id\")[\"score_bert\"].rank(ascending=0,method='dense')\n",
    "    output_df_chunk[\"bert_rank\"] = output_df_chunk['bert_rank'].astype(int)\n",
    "\n",
    "    # save\n",
    "    output_df_chunk[['query_id', 'passage_id', 'bm25_rank', 'score_bert', 'bert_rank']].to_csv(output_dir + output_filename + '-{}-of-{}'.format(i + 1, n_chunks),sep=\"\\t\", header=False,index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_df = pd.read_csv(msmarco_dir + 'qrels.dev.small.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "relevance_df.columns = ['query_id','label1','passage_id','label2']\n",
    "relevance_df = relevance_df.drop(columns=['label1','label2'])\n",
    "\n",
    "bert_filenames = [output_filename + '-{}-of-{}'.format(i + 1, n_chunks) for i in range(n_chunks)]\n",
    "\n",
    "bert_dfs = []\n",
    "for bert_filename in tqdm(bert_filenames):\n",
    "    bert_df = pd.read_csv(output_dir + bert_filename,delimiter='\\t',encoding='utf-8', header=None)\n",
    "    bert_df.columns = ['query_id', 'passage_id', 'bm25_rank', 'bert_score', 'bert_rank']\n",
    "    bert_dfs.append(bert_df)\n",
    " \n",
    "bert_rankings = pd.concat(bert_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mrr(gt, pred, column):\n",
    "   score = 0.0\n",
    "   best_rank = 11\n",
    "   for index, row in pred.iterrows():\n",
    "       current_rank = row[column]\n",
    "       if row['passage_id'] in gt:\n",
    "           if current_rank < best_rank:\n",
    "               score = 1.0 / (row[column])\n",
    "               best_rank = current_rank\n",
    "   return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_mrr = 0.0\n",
    "bert_mrr = 0.0\n",
    "\n",
    "query_ids = list(np.unique(bert_rankings['query_id'].tolist()))\n",
    "relevance_df = relevance_df[relevance_df['query_id'].isin(query_ids)]\n",
    "for query_id in tqdm(query_ids):\n",
    "    gt = relevance_df[relevance_df['query_id'] == query_id]['passage_id'].values.tolist()\n",
    "\n",
    "    query_preds_df = bert_rankings[(bert_rankings['query_id'] == query_id) & (bert_rankings['bert_rank'] < 11)]\n",
    "    bert_mrr += compute_mrr(gt, query_preds_df, 'bert_rank')\n",
    "\n",
    "    query_preds_df = bert_rankings[(bert_rankings['query_id'] == query_id) & (bert_rankings['bm25_rank'] < 11)]\n",
    "    bm25_mrr += compute_mrr(gt, query_preds_df, 'bm25_rank')\n",
    "\n",
    "tqdm.write('BM25: MRR@10: {}'.format(round((bm25_mrr/len(query_ids))*100,1)))\n",
    "tqdm.write('BERT: MRR@10: {}'.format(round((bert_mrr/len(query_ids))*100,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ir-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f918abf570f977e2e50fa3541a1cc05f77aa7d7291c6ebc3d2aa5f013fa00f4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
